# search_similar_bags.py (ì‹œê°í™” ê°•í™” ë²„ì „)

import os
from dotenv import load_dotenv
import supabase
from PIL import Image
from transformers import CLIPProcessor, CLIPModel
import torch
import matplotlib.pyplot as plt
import requests
from io import BytesIO
import numpy as np # np.argsort ë“±ì„ ìœ„í•´ ì¶”ê°€

# --- ( PNG ì²˜ë¦¬ í•¨ìˆ˜) ---
def convert_png_to_rgb_with_white_bg(image):
    if image.mode == 'RGBA':
        background = Image.new("RGB", image.size, (255, 255, 255))
        background.paste(image, mask=image.split()[3])
        return background
    else:
        return image.convert("RGB")

# --- (ìƒˆë¡œìš´ ì‹œê°í™” í•¨ìˆ˜ ì¶”ê°€) ---
def display_results(query_img, results_data, top_k):
    """
    ì¿¼ë¦¬ ì´ë¯¸ì§€ì™€ ìœ ì‚¬ë„ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í•¨ê»˜ ì‹œê°í™”í•©ë‹ˆë‹¤.
    """
    if not results_data:
        print("\nğŸ¤” ìœ ì‚¬í•œ ìƒí’ˆì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return

    # ì¿¼ë¦¬ ì´ë¯¸ì§€ 1ê°œ + ê²°ê³¼ ì´ë¯¸ì§€ë“¤ (ìµœëŒ€ top_kê°œ)
    num_display = min(len(results_data), top_k) + 1 
    
    fig, axes = plt.subplots(1, num_display, figsize=(3 * num_display, 4)) # figsize ì¡°ì •
    
    # axesê°€ 1ê°œì¼ ë•Œ np.arrayë¡œ ê°ì‹¸ì„œ í•­ìƒ ë°°ì—´ì²˜ëŸ¼ ë‹¤ë£° ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.
    # ê²°ê³¼ê°€ 0ê°œê°€ ì•„ë‹ˆê¸° ë•Œë¬¸ì— ì´ ë¶€ë¶„ì€ ì•ˆì „í•©ë‹ˆë‹¤.
    axes_flat = axes.flatten() 

    # ì¿¼ë¦¬ ì´ë¯¸ì§€ í‘œì‹œ (ê°€ì¥ ì™¼ìª½)
    axes_flat[0].imshow(query_img)
    axes_flat[0].set_title("Query Bag")
    axes_flat[0].axis('off')

    print("\n--- ğŸ” ìµœì¢… ê²€ìƒ‰ ê²°ê³¼ ---")
    for i, item in enumerate(results_data):
        if i >= top_k: # top_kê¹Œì§€ë§Œ í‘œì‹œ
            break

        # 'thumbnail' ëŒ€ì‹  'image_url'ì„ ì‚¬ìš©í•˜ê³  ì‹¶ë‹¤ë©´ item['image_url']ë¡œ ë³€ê²½
        # í•˜ì§€ë§Œ bags í…Œì´ë¸”ì—ëŠ” 'thumbnail' ì»¬ëŸ¼ì´ ë” ì í•©í•©ë‹ˆë‹¤.
        image_to_display_url = item.get('thumbnail') 
        similarity_score = item['similarity'] * 100
        
        print(f"{i+1}ìˆœìœ„: {item.get('bag_name', 'N/A')} by {item.get('brand', 'N/A')} (ìœ ì‚¬ë„: {similarity_score:.2f}%)")
        
        if image_to_display_url:
            try:
                # URLì—ì„œ ì´ë¯¸ì§€ ë¡œë“œ
                res = requests.get(image_to_display_url, stream=True)
                res.raise_for_status() # HTTP ì˜¤ë¥˜ ë°œìƒ ì‹œ ì˜ˆì™¸ ë°œìƒ
                img_from_url = Image.open(BytesIO(res.content))
                axes_flat[i+1].imshow(img_from_url)
                axes_flat[i+1].set_title(f"Rank {i+1}\n{item.get('bag_name', '')}", fontsize=8)
            except Exception as img_err:
                print(f"    - ğŸš¨ ì˜¤ë¥˜: {image_to_display_url} ë¡œë“œ ì‹¤íŒ¨: {img_err}")
                axes_flat[i+1].set_title(f"Rank {i+1}\nImage Load Error", fontsize=8)
        else:
            axes_flat[i+1].set_title(f"Rank {i+1}\nNo Image URL", fontsize=8)
        
        axes_flat[i+1].axis('off')

    plt.tight_layout()
    plt.show()


# --- 1. ì´ˆê¸°í™” ---
print("1. ëª¨ë¸ ë° í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤...")
load_dotenv()
device = "cuda" if torch.cuda.is_available() else "cpu"

clip_model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32").to(device)
clip_processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")

supabase_url = os.environ.get("SUPABASE_URL")
supabase_key = os.environ.get("SUPABASE_KEY")
client = supabase.create_client(supabase_url, supabase_key)
print("âœ… ì´ˆê¸°í™” ì™„ë£Œ.")

# --- 2. ê²€ìƒ‰ ì‹¤í–‰ ---
# ğŸ‘ˆ ì—¬ê¸°ì— ê²€ìƒ‰í•˜ê³  ì‹¶ì€ ì´ë¯¸ì§€ì˜ 'ë¡œì»¬ ê²½ë¡œ'ë¥¼ ì…ë ¥í•˜ì„¸ìš”.
# ì°¸ê³ : ì´ ì´ë¯¸ì§€ëŠ” DBì— ì—†ëŠ” ìƒˆë¡œìš´ ì´ë¯¸ì§€ì—¬ë„ ë©ë‹ˆë‹¤.
query_image_path = "./embedding_test_Img/embedding_test_img.png"
top_k = 3 # ìœ ì‚¬ë„ ë†’ì€ ìƒìœ„ 3ê°œë§Œ í‘œì‹œí•˜ë„ë¡ ì„¤ì •

try:
    print(f"\n--- ê²€ìƒ‰ ì‹œì‘: {query_image_path} ---")
    query_image = Image.open(query_image_path)
    query_image_rgb = convert_png_to_rgb_with_white_bg(query_image)

    # ì¿¼ë¦¬ ì´ë¯¸ì§€ ë²¡í„°í™”
    inputs = clip_processor(images=query_image_rgb, return_tensors="pt").to(device)
    with torch.no_grad():
        query_embedding = clip_model.get_image_features(**inputs).cpu().numpy().tolist()[0]

    # Supabaseì˜ 'search_similar_bags' í•¨ìˆ˜ í˜¸ì¶œ
    response = client.rpc('search_similar_bags', {
        'query_embedding': query_embedding,
        'match_threshold': 0.7, 
        'match_count': top_k # top_k ê°œìˆ˜ë§Œí¼ë§Œ ìš”ì²­
    }).execute()
    
    results_data = response.data
    
    # --- 3. ê²°ê³¼ ì‹œê°í™” í•¨ìˆ˜ í˜¸ì¶œ ---
    display_results(query_image_rgb, results_data, top_k)

except FileNotFoundError:
    print(f"ğŸš¨ ì˜¤ë¥˜: ì¿¼ë¦¬ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: '{query_image_path}'")
except Exception as e:
    print(f"ğŸš¨ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")